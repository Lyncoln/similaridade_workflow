<workflow xmlns="http://taverna.sf.net/2008/xml/t2flow" version="1" producedBy="taverna-2.4.0"><dataflow id="b7fbec18-07cc-4451-8b40-0c3c1ed9288e" role="top"><name>ARC2WARC_Hadoop_Job</name><inputPorts><port><name>hdfs_input_path</name><depth>0</depth><granularDepth>0</granularDepth><annotations><annotation_chain encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.FreeTextDescription">
        <text>HDFS input directory</text>
      </annotationBean>
      <date>2014-03-06 09:51:19.728 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain><annotation_chain encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.ExampleValue">
        <text>hdfs:///user/output/directory</text>
      </annotationBean>
      <date>2014-03-06 09:51:45.877 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain></annotations></port><port><name>hdfs_output_path</name><depth>0</depth><granularDepth>0</granularDepth><annotations><annotation_chain encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.ExampleValue">
        <text>hdfs:///user/input/directory</text>
      </annotationBean>
      <date>2014-03-06 09:51:38.197 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain><annotation_chain encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.FreeTextDescription">
        <text>HDFS input directory</text>
      </annotationBean>
      <date>2014-03-06 09:51:22.206 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain></annotations></port></inputPorts><outputPorts><port><name>hadoop_fs_ls_STDOUT</name><annotations /></port><port><name>arc2warc_hdp_STDOUT</name><annotations /></port></outputPorts><processors><processor><name>arc2warc_hdp</name><inputPorts><port><name>hadoop_job_jar_path</name><depth>0</depth></port><port><name>hdfs_input_path</name><depth>0</depth></port><port><name>hdfs_output_path</name><depth>0</depth></port></inputPorts><outputPorts><port><name>STDOUT</name><depth>0</depth><granularDepth>0</granularDepth></port></outputPorts><annotations /><activities><activity><raven><group>net.sf.taverna.t2.activities</group><artifact>external-tool-activity</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.activities.externaltool.ExternalToolActivity</class><inputMap><map from="hdfs_output_path" to="hdfs_output_path" /><map from="hdfs_input_path" to="hdfs_input_path" /><map from="hadoop_job_jar_path" to="hadoop_job_jar_path" /></inputMap><outputMap><map from="STDOUT" to="STDOUT" /></outputMap><configBean encoding="xstream"><net.sf.taverna.t2.activities.externaltool.ExternalToolActivityConfigurationBean xmlns="">
  <group>
    <invocationGroupName>default</invocationGroupName>
    <mechanismType>D0A4CDEB-DD10-4A8E-A49C-8871003083D8</mechanismType>
    <mechanismName>cluster</mechanismName>
    <mechanismXML>&lt;?xml version="1.0" encoding="UTF-8"?&gt;&#xD;
&lt;sshInvocation&gt;&lt;sshNode&gt;&lt;host&gt;fue-hdc01&lt;/host&gt;&lt;port&gt;22&lt;/port&gt;&lt;directory&gt;/tmp/&lt;/directory&gt;&lt;linkCommand&gt;/bin/ln -s %%PATH_TO_ORIGINAL%% %%TARGET_NAME%%&lt;/linkCommand&gt;&lt;copyCommand&gt;/bin/cp %%PATH_TO_ORIGINAL%% %%TARGET_NAME%%&lt;/copyCommand&gt;&lt;/sshNode&gt;&lt;/sshInvocation&gt;&#xD;
</mechanismXML>
  </group>
  <externaltoolid>272a19a9-2322-44bf-af5c-afd14a24dbef</externaltoolid>
  <useCaseDescription>
    <usecaseid />
    <description />
    <command># usage: hadoop jar
#        target/arc2warc-migration-1.0-SNAPSHOT-jar-with-dependencies.jar
#        [-a &lt;arg&gt;] [-c] [-h] [-i &lt;arg&gt;] [-l] [-o &lt;arg&gt;] [-p] [-t] [-x
#        &lt;arg&gt;]
#  -a,--arc2hwar &lt;arg&gt;   ARC to HWAR mapping file path. [optional].
#  -c,--comprwarc        Create compressed WARC file. [optional].
#  -h,--help             print this message [optional].
#  -i,--input &lt;arg&gt;      HDFS Input directory with ARC files. [required].
#  -l,--local            Use local file system instead of HDFS (debugging).
#                        [optional].
#  -o,--output &lt;arg&gt;     HDFS Output directory where the WARC files will be
#                        stored. [required].
#  -p,--payloadid        Do payload mime type identification. [optional].
#  -t,--localtest        Starting application as a local java application
#                        without hadoop (testing). [optional].
#  -x,--iregex &lt;arg&gt;     Only input paths matching the regular expression
#                        will be processed. [optional].
hadoop jar %%hadoop_job_jar_path%% -i %%hdfs_input_path%% -o %%hdfs_output_path%%</command>
    <preparingTimeoutInSeconds>1200</preparingTimeoutInSeconds>
    <executionTimeoutInSeconds>1800</executionTimeoutInSeconds>
    <tags>
      <string>hadoop_job_jar_path</string>
      <string>hdfs_input_path</string>
      <string>hdfs_output_path</string>
    </tags>
    <REs />
    <queue__preferred />
    <queue__deny />
    <static__inputs />
    <inputs>
      <entry>
        <string>hdfs_output_path</string>
        <de.uni__luebeck.inb.knowarc.usecases.ScriptInputUser>
          <tag>hdfs_output_path</tag>
          <file>false</file>
          <tempFile>false</tempFile>
          <binary>false</binary>
          <charsetName>UTF-8</charsetName>
          <forceCopy>false</forceCopy>
          <list>false</list>
          <concatenate>false</concatenate>
          <mime />
        </de.uni__luebeck.inb.knowarc.usecases.ScriptInputUser>
      </entry>
      <entry>
        <string>hdfs_input_path</string>
        <de.uni__luebeck.inb.knowarc.usecases.ScriptInputUser>
          <tag>hdfs_input_path</tag>
          <file>false</file>
          <tempFile>false</tempFile>
          <binary>false</binary>
          <charsetName>UTF-8</charsetName>
          <forceCopy>false</forceCopy>
          <list>false</list>
          <concatenate>false</concatenate>
          <mime />
        </de.uni__luebeck.inb.knowarc.usecases.ScriptInputUser>
      </entry>
      <entry>
        <string>hadoop_job_jar_path</string>
        <de.uni__luebeck.inb.knowarc.usecases.ScriptInputUser>
          <tag>hadoop_job_jar_path</tag>
          <file>false</file>
          <tempFile>false</tempFile>
          <binary>false</binary>
          <charsetName>UTF-8</charsetName>
          <forceCopy>false</forceCopy>
          <list>false</list>
          <concatenate>false</concatenate>
          <mime />
        </de.uni__luebeck.inb.knowarc.usecases.ScriptInputUser>
      </entry>
    </inputs>
    <outputs />
    <includeStdIn>false</includeStdIn>
    <includeStdOut>true</includeStdOut>
    <includeStdErr>true</includeStdErr>
    <validReturnCodes>
      <int>0</int>
    </validReturnCodes>
  </useCaseDescription>
  <edited>false</edited>
</net.sf.taverna.t2.activities.externaltool.ExternalToolActivityConfigurationBean></configBean><annotations /></activity></activities><dispatchStack><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Parallelize</class><configBean encoding="xstream"><net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ParallelizeConfig xmlns="">
  <maxJobs>1</maxJobs>
</net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ParallelizeConfig></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ErrorBounce</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Failover</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Retry</class><configBean encoding="xstream"><net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.RetryConfig xmlns="">
  <backoffFactor>1.0</backoffFactor>
  <initialDelay>1000</initialDelay>
  <maxDelay>5000</maxDelay>
  <maxRetries>0</maxRetries>
</net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.RetryConfig></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Invoke</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer></dispatchStack><iterationStrategyStack><iteration><strategy><cross><port name="hadoop_job_jar_path" depth="0" /><port name="hdfs_input_path" depth="0" /><port name="hdfs_output_path" depth="0" /></cross></strategy></iteration></iterationStrategyStack></processor><processor><name>hadoop_job_jar_path</name><inputPorts /><outputPorts><port><name>value</name><depth>0</depth><granularDepth>0</granularDepth></port></outputPorts><annotations /><activities><activity><raven><group>net.sf.taverna.t2.activities</group><artifact>stringconstant-activity</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.activities.stringconstant.StringConstantActivity</class><inputMap /><outputMap><map from="value" to="value" /></outputMap><configBean encoding="xstream"><net.sf.taverna.t2.activities.stringconstant.StringConstantConfigurationBean xmlns="">
  <value>/home/onbfue/arc2warc-migration-hdp-1.0-jar-with-dependencies.jar</value>
</net.sf.taverna.t2.activities.stringconstant.StringConstantConfigurationBean></configBean><annotations /></activity></activities><dispatchStack><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Parallelize</class><configBean encoding="xstream"><net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ParallelizeConfig xmlns="">
  <maxJobs>1</maxJobs>
</net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ParallelizeConfig></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ErrorBounce</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Failover</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Retry</class><configBean encoding="xstream"><net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.RetryConfig xmlns="">
  <backoffFactor>1.0</backoffFactor>
  <initialDelay>1000</initialDelay>
  <maxDelay>5000</maxDelay>
  <maxRetries>0</maxRetries>
</net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.RetryConfig></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Invoke</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer></dispatchStack><iterationStrategyStack><iteration><strategy /></iteration></iterationStrategyStack></processor><processor><name>hadoop_fs_ls</name><inputPorts><port><name>hdfs_output_path</name><depth>0</depth></port></inputPorts><outputPorts><port><name>STDOUT</name><depth>0</depth><granularDepth>0</granularDepth></port></outputPorts><annotations /><activities><activity><raven><group>net.sf.taverna.t2.activities</group><artifact>external-tool-activity</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.activities.externaltool.ExternalToolActivity</class><inputMap><map from="hdfs_output_path" to="hdfs_output_path" /></inputMap><outputMap><map from="STDOUT" to="STDOUT" /></outputMap><configBean encoding="xstream"><net.sf.taverna.t2.activities.externaltool.ExternalToolActivityConfigurationBean xmlns="">
  <mechanismType>789663B8-DA91-428A-9F7D-B3F3DA185FD4</mechanismType>
  <mechanismName>default local</mechanismName>
  <mechanismXML>&lt;?xml version="1.0" encoding="UTF-8"?&gt;&#xD;
&lt;localInvocation&gt;&lt;shellPrefix&gt;/bin/sh -c&lt;/shellPrefix&gt;&lt;linkCommand&gt;/bin/ln -s %%PATH_TO_ORIGINAL%% %%TARGET_NAME%%&lt;/linkCommand&gt;&lt;/localInvocation&gt;&#xD;
</mechanismXML>
  <externaltoolid>72850451-c560-4cb8-843f-08e7eea633d7</externaltoolid>
  <useCaseDescription>
    <usecaseid />
    <description />
    <command>hadoop fs -ls %%hdfs_output_path%%</command>
    <preparingTimeoutInSeconds>1200</preparingTimeoutInSeconds>
    <executionTimeoutInSeconds>1800</executionTimeoutInSeconds>
    <tags>
      <string>hdfs_output_path</string>
    </tags>
    <REs />
    <queue__preferred />
    <queue__deny />
    <static__inputs />
    <inputs>
      <entry>
        <string>hdfs_output_path</string>
        <de.uni__luebeck.inb.knowarc.usecases.ScriptInputUser>
          <tag>hdfs_output_path</tag>
          <file>false</file>
          <tempFile>false</tempFile>
          <binary>false</binary>
          <charsetName>UTF-8</charsetName>
          <forceCopy>false</forceCopy>
          <list>false</list>
          <concatenate>false</concatenate>
          <mime />
        </de.uni__luebeck.inb.knowarc.usecases.ScriptInputUser>
      </entry>
    </inputs>
    <outputs />
    <includeStdIn>false</includeStdIn>
    <includeStdOut>true</includeStdOut>
    <includeStdErr>true</includeStdErr>
    <validReturnCodes>
      <int>0</int>
    </validReturnCodes>
  </useCaseDescription>
  <edited>false</edited>
</net.sf.taverna.t2.activities.externaltool.ExternalToolActivityConfigurationBean></configBean><annotations /></activity></activities><dispatchStack><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Parallelize</class><configBean encoding="xstream"><net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ParallelizeConfig xmlns="">
  <maxJobs>1</maxJobs>
</net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ParallelizeConfig></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.ErrorBounce</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Failover</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Retry</class><configBean encoding="xstream"><net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.RetryConfig xmlns="">
  <backoffFactor>1.0</backoffFactor>
  <initialDelay>1000</initialDelay>
  <maxDelay>5000</maxDelay>
  <maxRetries>0</maxRetries>
</net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.RetryConfig></configBean></dispatchLayer><dispatchLayer><raven><group>net.sf.taverna.t2.core</group><artifact>workflowmodel-impl</artifact><version>1.4</version></raven><class>net.sf.taverna.t2.workflowmodel.processor.dispatch.layers.Invoke</class><configBean encoding="xstream"><null xmlns="" /></configBean></dispatchLayer></dispatchStack><iterationStrategyStack><iteration><strategy><cross><port name="hdfs_output_path" depth="0" /></cross></strategy></iteration></iterationStrategyStack></processor></processors><conditions><condition control="arc2warc_hdp" target="hadoop_fs_ls" /></conditions><datalinks><datalink><sink type="processor"><processor>arc2warc_hdp</processor><port>hadoop_job_jar_path</port></sink><source type="processor"><processor>hadoop_job_jar_path</processor><port>value</port></source></datalink><datalink><sink type="processor"><processor>arc2warc_hdp</processor><port>hdfs_input_path</port></sink><source type="dataflow"><port>hdfs_input_path</port></source></datalink><datalink><sink type="processor"><processor>arc2warc_hdp</processor><port>hdfs_output_path</port></sink><source type="dataflow"><port>hdfs_output_path</port></source></datalink><datalink><sink type="processor"><processor>hadoop_fs_ls</processor><port>hdfs_output_path</port></sink><source type="dataflow"><port>hdfs_output_path</port></source></datalink><datalink><sink type="dataflow"><port>hadoop_fs_ls_STDOUT</port></sink><source type="processor"><processor>hadoop_fs_ls</processor><port>STDOUT</port></source></datalink><datalink><sink type="dataflow"><port>arc2warc_hdp_STDOUT</port></sink><source type="processor"><processor>arc2warc_hdp</processor><port>STDOUT</port></source></datalink></datalinks><annotations><annotation_chain encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.DescriptiveTitle">
        <text>ARC2WARC Hadoop Job</text>
      </annotationBean>
      <date>2014-03-06 09:53:06.302 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain><annotation_chain_2_2 encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.IdentificationAssertion">
        <identification>c65e2854-5451-4d20-8e80-67587b45687a</identification>
      </annotationBean>
      <date>2014-03-06 09:54:02.565 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain_2_2><annotation_chain_2_2 encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.IdentificationAssertion">
        <identification>b7fbec18-07cc-4451-8b40-0c3c1ed9288e</identification>
      </annotationBean>
      <date>2014-03-06 09:57:15.411 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain_2_2><annotation_chain encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.FreeTextDescription">
        <text>Just a wrapper workflow for a Hadoop job converting ARC to WARC files.</text>
      </annotationBean>
      <date>2014-03-06 09:53:29.317 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain><annotation_chain encoding="xstream"><net.sf.taverna.t2.annotation.AnnotationChainImpl xmlns="">
  <annotationAssertions>
    <net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
      <annotationBean class="net.sf.taverna.t2.annotation.annotationbeans.Author">
        <text>Sven Schlarb</text>
      </annotationBean>
      <date>2014-03-06 09:53:09.245 UTC</date>
      <creators />
      <curationEventList />
    </net.sf.taverna.t2.annotation.AnnotationAssertionImpl>
  </annotationAssertions>
</net.sf.taverna.t2.annotation.AnnotationChainImpl></annotation_chain></annotations></dataflow></workflow>